python train.py taoteba  logs/logs_taoteba_LSTM  --learning_rate=10 --add_char_emb=False --weighted_loss=False --add_encoder=False --deepness_finish=0 --n_epochs=1 --batch_size=256